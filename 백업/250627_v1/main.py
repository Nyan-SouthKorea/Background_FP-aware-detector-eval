# ê¸°ë³¸
import os
import json
import copy

# pip install
from natsort import natsorted
from tqdm import tqdm
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from sklearn.metrics import confusion_matrix
import seaborn as sns
import itertools

# custom
try:
    print('utils import 1')
    from utils import *
except:
    print('utils import 2')
    from mAP_eval.utils import *

class Eval_Object_Detector:
    '''
    ì‚¬ë¬¼ ì¸ì‹ ëª¨ë¸ì˜ Conf. Thresh. ë³„ Precision, Recall ì¸¡ì •
    '''
    def __init__(self, path_gt, path_pred, class_list, path_output):
        '''
        ëª¨ë“ˆì„ ì²˜ìŒ ì‹¤í–‰í•  ë•Œ ê¸°ë³¸ì ìœ¼ë¡œ ì…ë ¥í•´ì•¼ í•˜ëŠ” ê°’

        args:
        path_gt = ì›ë³¸ ë ˆì´ë¸” txtê°€ ë‹´ê²¨ìˆëŠ” í´ë” ê²½ë¡œ
            - YOLO label í˜•ì‹ìœ¼ë¡œ YOLOv7ì˜ test.pyì—ì„œ --save-txt, --save-confë¥¼ ì…ë ¥í–ˆì„ ë•Œ ì¶œë ¥ë˜ëŠ” ë ˆì´ë¸” í˜•ì‹
            - class_no(int) x_center y_center width heightë¡œ ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ êµ¬ë¶„ë˜ë©°, ë‹¤ìŒ bboxëŠ” ì—”í„°ë¡œ êµ¬ë¶„ë¨
        path_pred = YOLO label í˜•ì‹ìœ¼ë¡œ ì˜ˆì¸¡ëœ íŒŒì¼ì˜ í´ë” ì£¼ì†Œ
            - ìì„¸í•œ ì„¤ëª…ì€ path_gt í˜•ì‹ê³¼ ë™ì¼í•¨
            - class_no(int) x_center y_center width height confidenceë¡œ ìŠ¤í˜ì´ìŠ¤ë°”ë¡œ êµ¬ë¶„ë˜ë©°, ë‹¤ìŒ bboxëŠ” ì—”í„°ë¡œ êµ¬ë¶„ë¨
        class_list = ê°ì²´ ë¦¬ìŠ¤íŠ¸ ì…ë ¥
            - e.g. ['cable', 'person', 'cat']
        path_output = ê²°ê³¼ë¥¼ ì €ì¥í•˜ëŠ” ê²½ë¡œ
        '''
        print('ì½”ë“œ ë¦´ë¦¬ì¦ˆ ë‚ ì§œ: 250416_v1')
        print('evaluate() ì´ìš© ì‹œ ì „ì²´ì ì¸ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.')
        print('1íšŒ í‰ê°€ ì´í›„ draw_bgfp_auto(path_img) ì´ìš© ì‹œ Background FPì— ëŒ€í•œ ì‚¬ë¡€ë“¤ì„ ê·¸ë ¤ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n')

        self.path_gt = path_gt
        self.path_pred = path_pred
        self.class_list = class_list
        self.path_output = path_output
        self.iou_thresh_list = [0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8, 0.85, 0.9, 0.95]

        # í´ë” ìƒì„±
        makedirs(self.path_output)

        # conf. thresh. ê´€ë ¨ ì„¤ì •
        self.conf_thresh_list = []
        conf_thresh_step = 1000
        for i in range(conf_thresh_step): self.conf_thresh_list.append(i/conf_thresh_step)
        # (ì²« ë²ˆì§¸ conf. thresh.ì—ì„œì˜ ì •ë³´ë§Œ ê¸°ë¡í•˜ê¸° ì›í•  ë•Œ ì¡°ê±´ë¬¸ìœ¼ë¡œ ì‚¬ìš©)
        self.first_conf_step = (self.conf_thresh_list[0] + self.conf_thresh_list[1])/2

        # ê¸°ë³¸ì ìœ¼ë¡œ í•„ìš”í•œ pred, gt ë¶ˆëŸ¬ì˜¤ê¸°
        self.pred, self.gt = self._pred_and_gt_mapping()

        # ì¶”í›„ confusion matrixë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ ì„ ì–¸(self._cal_pr()ì—ì„œ ëª¨ë“  conf. thrsh.ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê¸°ë¡í•œë‹¤.)
        self._make_confusion_matrix_dic()

    def evaluate(self):
        '''
        mAP@0.5, mAP@0.5:0.95, PR í‰ê°€ ë° ê·¸ë˜í”„ ì¶œë ¥ ë“± ëª¨ë“  ê¸°ëŠ¥ ì „ì²´ ìë™í™”
        '''
        # ìµœì¢… ê²°ê³¼ì°½ì— ë‚˜íƒ€ë‚˜ëŠ” images ê°œìˆ˜ì™€ labels ê°œìˆ˜ ì¶œë ¥ì„ ìœ„í•´ ê³„ì‚°
        images, labels, total_images = self.get_images_and_labels()

        # prê³¼ mAP ê³„ì‚°
        pr_results = self.get_PR()
        best_p, best_r, best_f1, best_conf_thresh = self._get_best_f1score_and_confidence_threshold(pr_results)
        self._draw_confusion_matrix(best_conf_thresh, pr_results)
        mAP_05, mAP_0595 = self.get_mAP()

        # ê²°ê³¼ í‘œë¥¼ ë§Œë“¤ê¸° ìœ„í•´ all ì˜ì—­ ê³„ì‚° ë° í‘œ ë§Œë“¤ê¸°
        # (Class)
        df_class = ['all']
        for class_name in self.class_list:
            df_class.append(class_name)
        # (Images)
        df_images = [total_images]
        for image in images.values():
            df_images.append(image)
        # (Labels)
        df_labels = [sum(list(labels.values()))]
        for label in labels.values():
            df_labels.append(label)
        # (P)
        p_list = list(best_p.values())
        df_p = [self.rnd(sum(p_list)/len(p_list))]
        for p in p_list:
            df_p.append(self.rnd(p))
        # (R)
        r_list = list(best_r.values())
        df_r = [self.rnd(sum(r_list)/len(r_list))]
        for r in r_list:
            df_r.append(self.rnd(r))
        # (mAP@0.5)
        mAP_05_list = list(mAP_05.values())
        df_mAP_05 = [self.rnd(sum(mAP_05_list)/len(mAP_05_list))]
        for mAP in mAP_05_list:
            df_mAP_05.append(self.rnd(mAP))
        # (mAP@0.5:0.95)
        mAP_0595_list = list(mAP_0595.values())
        df_mAP_0595 = [self.rnd(sum(mAP_0595_list)/len(mAP_0595_list))]
        for mAP in mAP_0595_list:
            df_mAP_0595.append(self.rnd(mAP))
        # (F1_score)
        f1_list = list(best_f1.values())
        df_f1 = [self.rnd(sum(f1_list)/len(f1_list))]
        for f1 in f1_list:
            df_f1.append(self.rnd(f1))
        # (conf. thresh.)
        conf_thresh_list = list(best_conf_thresh.values())
        df_conf_thresh = [self.rnd(sum(conf_thresh_list)/len(conf_thresh_list))]
        for ct in conf_thresh_list:
            df_conf_thresh.append(self.rnd(ct))
        
        # Pandas DataFrame ë§Œë“¤ê¸°
        data = {'Class':df_class,
        'Images':df_images, 
        'Labels':df_labels,
        '      P':df_p,
        '      R':df_r,
        'mAP@.5':df_mAP_05,
        'mAP@.5:.95':df_mAP_0595,
        'F1_score':df_f1,
        'Conf. Thr.':df_conf_thresh,
        }

        df_result = pd.DataFrame(data)

        # í„°ë¯¸ë„ ì¶œë ¥
        print("\n=== Evaluation Results ===\n")
        print(df_result.to_string(index=False))

        # CSVë¡œ ì €ì¥
        csv_path = os.path.join(self.path_output, 'evaluation_summary.csv')
        df_result.to_csv(csv_path, index=False)
        print(f"\nCSV saved to: {csv_path}")
        
    def _make_confusion_matrix_dic(self):
        '''
        Concusion Matrixë¥¼ ê·¸ë¦´ ìˆ˜ ìˆë„ë¡ ë°ì´í„°ë¥¼ ìŒ“ê¸° ìœ„í•´ ì´ˆë°˜ì— ì„ ì–¸í•´ ë†“ëŠ” ë°ì´í„° ì €ì¥ì†Œ
        - self._cal_pr()ì—ì„œ ëª¨ë“  conf. thresh. ë¥¼ ê¸°ì¤€ìœ¼ëŸ¬ ë°ì´í„°ë¥¼ ìŒ“ì•„ë†“ê³ 
        - ë‚˜ì¤‘ì— ê·¸ë¦´ ë•Œ self._draw_confusion_matrix()ì—ì„œ best conf. thresh. ê¸°ì¤€ìœ¼ë¡œ ê±¸ë ¤ì„œ ìƒˆë¡œ ê·¸ë¦°ë‹¤.
        - ì´ ë°©ë²•ìœ¼ ì¨ì•¼ì§€ ì²˜ìŒ í‰ê°€í•  ë•Œ ë¶€í„° ë°ì´í„°ë¥¼ ìŒ“ì•„ë†“ì„ ìˆ˜ ìˆìŒ
        '''
        # (2ì¤‘ dic ì†ì„± ë¨¼ì € ë§Œë“¤ê¸°)
        pred_dic = {'background_FP':[]}
        for class_name in self.class_list:
            pred_dic[class_name] = []
        # (main dic ì†ì„± ì±„ìš°ê¸°)
        self.cm_gt = {'background_FN':copy.deepcopy(pred_dic)}
        for class_name in self.class_list:
            self.cm_gt[class_name] = copy.deepcopy(pred_dic)

    def _draw_confusion_matrix(self, best_conf_thresh, pr_results):
        '''
        F1 Scoreê°€ ê°€ì¥ ë†’ì„ ë•Œì˜ Conf. Thresh.ë¥¼ ê¸°ì¤€ìœ¼ë¡œ Confusion Matrixë¥¼ ê·¸ë ¤ì„œ ì €ì¥
        '''
        # í´ë˜ìŠ¤ ë¦¬ìŠ¤íŠ¸ì— background FP/FN í¬í•¨í•˜ì—¬ í™•ì¥
        all_classes = ['background_FP'] + self.class_list
        all_classes.append('background_FN')  # ìˆœì„œ: background_FP, cls1, cls2, ..., background_FN

        # y_true, y_predë¥¼ êµ¬ì¶•
        y_true = []
        y_pred = []

        for gt_class in self.cm_gt:
            for pred_class in self.cm_gt[gt_class]:
                conf_list = self.cm_gt[gt_class][pred_class]
                for conf in conf_list:
                    if conf >= best_conf_thresh[gt_class]:
                        y_true.append(gt_class)
                        y_pred.append(pred_class)


        # FN ë°ì´í„° ì¶”ê°€
        for class_name, conf_thresh in best_conf_thresh.items():
            fn = pr_results[conf_thresh][class_name]['fn']
            for _ in range(fn):
                y_true.append(class_name)
                y_pred.append('background_FN')



        # confusion matrix ê³„ì‚°
        cm = confusion_matrix(y_true, y_pred, labels=all_classes)

        # ì‹œê°í™”
        plt.figure(figsize=(12, 10))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=all_classes, yticklabels=all_classes)
        plt.xlabel('Predicted Label')
        plt.ylabel('True Label')
        plt.title('Confusion Matrix')
        plt.tight_layout()

        # ì €ì¥
        save_path = os.path.join(self.path_output, f'Confusion_Matrix.png')
        plt.savefig(save_path)
        plt.close()
        print(f"Confusion Matrix saved to: {save_path}")



    def get_images_and_labels(self):
        '''
        ìµœì¢… ê²°ê³¼ì°½ì— ë‚˜íƒ€ë‚˜ëŠ” images ê°œìˆ˜ì™€ labels ê°œìˆ˜ ì¶œë ¥ì„ ìœ„í•´ ê³„ì‚°
        '''
        # ë¹„ì–´ìˆëŠ” dic ìƒì„±
        tmp = {}
        for class_name in self.class_list:
            tmp[class_name] = 0
        images, labels = copy.deepcopy(tmp), copy.deepcopy(tmp)
        
        # ì „ì²´ ì´ë¯¸ì§€ ê°œìˆ˜ ê³„ì‚°
        total_images = len(self.gt.keys())

        # ê³„ì‚°(images ê°œìˆ˜ì˜ ê²½ìš° í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— í•´ë‹¹ labelì´ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ì–´ìˆìœ¼ë©´ ì‚°ì •)
        for file_name, bbox_list in self.gt.items():
            # ì´ë¯¸ì§€ ë‚´ ê°ì²´ ì¡´ì¬ íŒë‹¨ì„ ìœ„í•œ bool dic ìƒì„±
            class_dic_bool = {}
            for class_name in self.class_list:
                class_dic_bool[class_name] = False
            
            # ê¸°ë¡
            for bbox in bbox_list:
                class_name = bbox['class_name']
                class_dic_bool[class_name] = True
                labels[class_name] += 1
            
            # images ê³„ì‚° ì ìš©
            for class_name, boolen in class_dic_bool.items():
                if boolen == True:
                    images[class_name] += 1
        
        return images, labels, total_images

    def get_mAP(self):
        '''
        mAP í‰ê°€ ì¢…í•© ìˆ˜í–‰
        '''
        # ì •ë‹µì§€ì™€ ì˜ˆì¸¡ì§€ ë¶ˆëŸ¬ì˜¤ê¸°      
        pred = copy.deepcopy(self.pred)
        gt = copy.deepcopy(self.gt)

        # 0.5 ~ 0.95ê¹Œì§€ ëª¨ë‘ ë‹´ì„ dic ì„ ì–¸
        mAP_0595 = {}
        for class_name in self.class_list:
            mAP_0595[class_name] = []

        # mAP@0.5:0.95 êµ¬í•˜ê¸°  
        for iou_thresh in tqdm(self.iou_thresh_list, desc='mAP@0.5:0.95 ê³„ì‚° ì¤‘...'):
            precision_dic, recall_dic = {}, {}
            conf_thresh_list = list(reversed(self.conf_thresh_list))
            for conf_thresh in conf_thresh_list:
                results = self._cal_pr(conf_thresh, iou_thresh, pred, gt)
                for class_name, result in results.items():
                    # precision ì›ì†Œ ì¶”ê°€
                    if class_name in precision_dic:
                        precision_dic[class_name].append(result['p'])
                    else:
                        precision_dic[class_name] = [result['p']]
                    
                    # recall ì›ì†Œ ì¶”ê°€
                    if class_name in recall_dic:
                        recall_dic[class_name].append(result['r'])
                    else:
                        recall_dic[class_name] = [result['r']]
            # ì‚¬ë‹¤ë¦¬ê¼´ ë³´ê°„ë²• ì ìš©
            for class_name in self.class_list:
                precision_dic[class_name] = self._interpolate_precision(precision_dic[class_name])

            # iou_threshê°€ 0.5ì¼ë•Œ PR ì»¤ë¸Œ ê·¸ë¦¬ê¸°
            if iou_thresh == 0.5:
                self._plot_pr_curve(precision_dic, recall_dic)
            
            # mAP0.5:0.95 êµ¬í•˜ê¸°
            mAP = self._get_pr_curve(precision_dic, recall_dic)
            for class_name, AP in mAP.items():
                mAP_0595[class_name].append(AP)
        
        # mAP@0.5 êµ¬í•˜ê¸°
        mAP_05 = {}
        for class_name, mAP_list in mAP_0595.items():
            mAP_05[class_name] = mAP_list[0]
        
        # mAP@0.5:0.95 êµ¬í•˜ê¸°
        for class_name, mAP_list in mAP_0595.items():
            av_mAP = sum(mAP_list) / len(mAP_list)
            mAP_0595[class_name] = av_mAP
        
        return mAP_05, mAP_0595
            
    def get_PR(self):
        '''
        mAPë¥¼ ì œì™¸í•œ precision, recall, f1-score ìˆ˜ì¹˜ ë° ê·¸ë˜í”„ ê·¸ë¦¬ê¸°
        '''
        # ì •ë‹µì§€ì™€ ì˜ˆì¸¡ì§€ ë¶ˆëŸ¬ì˜¤ê¸°        
        pred = copy.deepcopy(self.pred)
        gt = copy.deepcopy(self.gt)

        # conf_thresh ë³„ë¡œ ìˆ˜ì¹˜ ê³„ì‚°í•˜ê¸°
        results = {}
        for conf_thresh in tqdm(self.conf_thresh_list, desc='Precision, Recall ê³„ì‚° ì¤‘...'):
            results[conf_thresh] = self._cal_pr(conf_thresh, 0.5, pred, gt)
        
        # ê²°ê³¼ ì €ì¥
        self._plot_metrics(results)
        with open(f'{self.path_output}/results.json', 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=4)
        return results

    def _get_best_f1score_and_confidence_threshold(self, results):
        '''
        self.get_PR() ì—ì„œ ë„ì¶œëœ resultsë¥¼ ê¸°ë°˜ìœ¼ë¡œ best f1-scoreì— í•´ë‹¹í•˜ëŠ” pì™€ rì„ ë„ì¶œ
        '''
        # ë¹„ì–´ìˆëŠ” dic ìƒì„±
        tmp = {}
        for class_name in self.class_list:
            tmp[class_name] = 0
        best_p, best_r, best_f1, best_conf_thresh = copy.deepcopy(tmp), copy.deepcopy(tmp), copy.deepcopy(tmp), copy.deepcopy(tmp)

        # f1-scoreê°€ ê°€ì¥ ë†’ì€ ì‹œì  ê¸°ë¡ ì‹œì‘
        for class_name in self.class_list:
            for conf_thres, result in results.items():
                if best_f1[class_name] < result[class_name]['f1']:
                    best_f1[class_name] = result[class_name]['f1']
                    best_p[class_name] = result[class_name]['p']
                    best_r[class_name] = result[class_name]['r']
                    best_conf_thresh[class_name] = conf_thres
        return best_p, best_r, best_f1, best_conf_thresh

    def _get_pr_curve(self, precision_dic, recall_dic):
        '''PR ê·¸ë˜í”„ ë§Œë“¤ì–´ì„œ AP ë©´ì  êµ¬í•˜ê¸°'''
        aps = {}
        for class_name, precision_list in precision_dic.items():
            recall_list = recall_dic[class_name]
            ap = 0
            for i in range(len(precision_list)):
                # forë¬¸ ë‚˜ê°€ëŠ” ì¡°ê±´
                if i == len(precision_list)-2: break
                # ì‚¬ë‹¤ë¦¬ê¼´ ë©´ì  êµ¬í•˜ë©´ì„œ ë”í•˜ê¸°(ì•„ë˜ ì‚¬ê°í˜• + ìœ„ ì‚¼ê°í˜• ë”°ë¡œ ë©´ì  êµ¬í•´ì„œ ë”í•˜ê¸°)
                # (ì•„ë˜ ì‚¬ê°í˜• ë©´ì )
                width = recall_list[i+1] - recall_list[i]
                height = min(precision_list[i], precision_list[i+1])
                ap += (width * height)
                # (ìœ„ ì‚¼ê°í˜•)
                ap += ((width * (max(precision_list[i], precision_list[i+1])-height)) / 2)
            aps[class_name] = ap
        return aps

    def _interpolate_precision(self, precision_list):
        '''precisionì´ íŠ€ëŠ”ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´ ì ì§„ì ìœ¼ë¡œ ê°ì†Œë˜ëŠ” í˜•íƒœë¡œ ë³€í™˜'''
        new_list = []
        max_no = precision_list[-1]
        for precision in reversed(precision_list):
            if precision < max_no:
                precision = max_no
            else:
                max_no = precision
            new_list.append(precision)
        new_list.reverse()
        return new_list

    def _make_cm_result_dic(self, result, conf, pred_class, gt_class, label_name):
        '''mAP êµ¬í•˜ëŠ” ì–‘ì‹ì— ë§ê²Œ results ì•ˆì— íˆ¬ì…ë˜ëŠ” í•˜ë‚˜ì˜ ì›ì†Œë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ê¸°ëŠ¥'''
        return {'result':result, 'conf':conf, 'pred_class':pred_class, 'gt_class':gt_class}

    def _cal_pr(self, conf_thresh, iou_thresh, pred, gt):
        '''
        íŠ¹ì • class_nameì— ëŒ€í•´ì„œ ì§€ì •ëœ conf_threshë¡œ ì•„ë˜ì˜ ìˆ˜ì¹˜ë“¤ì„ ê³„ì‚°í•´ì¤Œ
            - precision
            - recall
            - background_fp = ì•„ë¬´ê²ƒë„ ì—†ëŠ” ë°°ê²½ì— ì˜¤ ì¸ì‹ì„ í•  í™•ë¥ . (background_fpê°œìˆ˜ / ì „ì²´ pred ê°œìˆ˜)
        '''
        # drawë¥¼ ìœ„í•´ background_fp ë¦¬ìŠ¤íŠ¸ ëª¨ì•„ë†“ê¸°
        if conf_thresh < self.first_conf_step:
            self.bgfp_list = []
                
        # confidence thresholdì— ë”°ë¼ í•„í„°ë§
        pred = self.filter_by_conf_thresh(pred, conf_thresh)

        # class_list ê¸°ì¤€ ì´ˆê¸° ì¹´ìš´í„° ì„¤ì •
        results = {}
        for class_name in self.class_list:
            results[class_name] = {'tp': 0, 'fp': 0, 'fn': 0, 'bg_fp': 0, 'total_gt': 0, 'total_pred': 0}
        
        # ê³„ì‚° ì‹œì‘
        for key in pred.keys():
            pred_bbox_list = pred[key]
            gt_bbox_list = gt[key]

            # gt ë°ì´í„°ì— matched í”Œë˜ê·¸ ì¶”ê°€
            for i in range(len(gt_bbox_list)):
                gt_bbox_list[i]['matched'] = False
            
            # predë¡œ ìˆœíšŒí•˜ë©° tp, fp ê²€ì¶œ
            for pred_bbox_data in pred_bbox_list:
                # pred ì›ì†Œ í•˜ë‚˜ë¥¼ ë¹¼ì„œ
                pred_class_name = pred_bbox_data['class_name']
                conf = pred_bbox_data['conf']
                pred_bbox = pred_bbox_data['bbox']
                # gt ì›ì†Œì™€ í•˜ë‚˜ì”© ë¹„êµí•œë‹¤.
                found = False
                for i, gt_bbox_data in enumerate(gt_bbox_list):
                    gt_class_name = gt_bbox_data['class_name']
                    gt_bbox = gt_bbox_data['bbox']
                    # iou ë§¤ì¹­ ì—¬ë¶€ í™•ì¸
                    if get_iou(pred_bbox, gt_bbox) >= iou_thresh:
                        # confusion matrix ê¸°ë¡
                        if conf_thresh < self.first_conf_step:
                            self.cm_gt[gt_class_name][pred_class_name].append(conf)
                        # ê°ì²´ ë§¤ì¹­ ì—¬ë¶€ í™•ì¸
                        if pred_class_name == gt_class_name:
                            gt_bbox_list[i]['matched'] = True
                            found = True
                            results[pred_class_name]['tp'] += 1
                            break
                if found == False:
                    results[pred_class_name]['fp'] += 1
                    # background_fp ê²€ì‚¬
                    if self._check_background_fp(pred_bbox_data, gt_bbox_list) == True:
                        results[pred_class_name]['bg_fp'] += 1
                        if conf_thresh < self.first_conf_step:
                            self.bgfp_list.append(pred_bbox_data)
                            self.bgfp_list[-1]['label_name'] = key
                            # confusion matrix ê¸°ë¡ 
                            self.cm_gt[pred_class_name]['background_FP'].append(conf)

            # pred ìˆœíšŒ ëë‚œ í›„ fn ê³„ì‚°
            for gt_bbox_data in gt_bbox_list:
                if gt_bbox_data['matched'] == False:
                    results[gt_bbox_data['class_name']]['fn'] += 1
        
        # total_predì™€ total_gt ê³„ì‚°
        # (pred)
        for bbox_list in pred.values():
            for bbox in bbox_list:
                class_name = bbox['class_name']
                results[class_name]['total_pred'] += 1
        # (gt)
        for bbox_list in gt.values():
            for bbox in bbox_list:
                class_name = bbox['class_name']
                results[class_name]['total_gt'] += 1


        # ìµœì¢… precision, recall, bg_fp ë¹„ìœ¨ ê³„ì‚°
        for class_name, result in results.items():
            tp = result['tp']
            fp = result['fp']
            fn = result['fn']
            bg_fp = result['bg_fp']
            result['bg_fp_cnt'] = result['bg_fp']
            total_pred = result['total_pred']
            total_gt = result['total_gt']
            results[class_name]['p'] = round(self._get_precision(tp, fp), 3)
            results[class_name]['r'] = round(self._get_recall(tp, fn), 3)
            results[class_name]['f1'] = (2 * results[class_name]['p'] * results[class_name]['r']) / max(0.00000001, (results[class_name]['p'] + results[class_name]['r']))
            results[class_name]['bg_fp'] = round(self._get_background_fp(bg_fp, total_pred), 3)

        return results


    def _check_background_fp(self, pred_bbox_data, gt_bbox_list):
        '''
        pred 1ê°œì™€ gt_bbox_listë¥¼ ë„£ì—ˆì„ ë•Œ, background_fp ì—¬ë¶€ë¥¼ ì•Œë ¤ì£¼ëŠ” í•¨ìˆ˜
        - ì…ë ¥ë˜ëŠ” pred_bbox_dataëŠ” fpì—¬ì•¼ í•¨
        - pred bboxì˜ 50%ë§Œ gt_bboxì— ê²¹ì³ìˆì–´ë„ background_fpê°€ ì•„ë‹Œê±¸ë¡œ ì¸ì •
        - classificationì´ í‹€ë ¤ë„ localizationë§Œ ë§ìœ¼ë©´ ëœë‹¤ëŠ” ì·¨ì§€
        '''
        pred_x1, pred_y1, pred_x2, pred_y2 = pred_bbox_data['bbox']
        pred_bbox_area = (pred_x2-pred_x1) * (pred_y2-pred_y1)
        found = False
        for gt_bbox_data in gt_bbox_list:
            gt_x1, gt_y1, gt_x2, gt_y2 = gt_bbox_data['bbox']
            # pred_bbox ì…ì¥ì—ì„œ ê²¹ì¹˜ëŠ” ë©´ì  ë„ì¶œ
            x1 = max(pred_x1, gt_x1)
            y1 = max(pred_y1, gt_y1)
            x2 = min(pred_x2, gt_x2)
            y2 = min(pred_y2, gt_y2)
            if (x2-x1) <= 0 or (y2-y1) <= 0:
                continue
            inter_area = (x2-x1) * (y2-y1)

            # ê²¹ì¹˜ëŠ” ë©´ì ì´ 50% ì´ìƒì¸ì§€ í™•ì¸
            if inter_area / pred_bbox_area >= 0.5:
                found = True
        
        # ê²°ê³¼ ë°˜í™˜
        if found == True:
            return False
        else:
            return True

    def _plot_metrics(self, results):        
        conf_thresholds = sorted([float(th) for th in results.keys()])

        metrics = {
            'p': ('Precision', 'Precision_curve.png'),
            'r': ('Recall', 'Recall_curve.png'),
            'bg_fp': ('Background FP', 'Background FP_curve.png'),
            'f1': ('F1-Score', 'F1-score_curve.png')
        }

        # ìƒ‰ìƒê³¼ ë¼ì¸ìŠ¤íƒ€ì¼ ì¡°í•© ìƒì„±ê¸°
        line_styles = ['-', '--'] # ['-', '--', '-.', ':']
        color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']
        style_combinations = list(itertools.product(color_cycle, line_styles))
        
        for metric_key, (metric_label, filename) in metrics.items():
            plt.figure(figsize=(12, 10), constrained_layout=True)  # ìë™ ì—¬ë°± ì¡°ì •
            
            for i, cls in enumerate(self.class_list):
                values = [results[conf][cls][metric_key] for conf in conf_thresholds]
                color, linestyle = style_combinations[i % len(style_combinations)]
                plt.plot(conf_thresholds, values, label=cls, linewidth=2.0,
                        linestyle=linestyle, color=color)

            # í‰ê· ì„ 
            mean_values = [
                sum(results[conf][cls][metric_key] for cls in self.class_list) / len(self.class_list)
                for conf in conf_thresholds
            ]
            plt.plot(conf_thresholds, mean_values, label='mean', linestyle='--', color='black', lw=3)

            plt.xlabel('Confidence Threshold')
            plt.ylabel(metric_label)
            plt.title(f'{metric_label} Curve')
            plt.grid(True)
            
            # ë²”ë¡€ ìœ„ì¹˜ ë° ê¸€ì í¬ê¸° ì¡°ì ˆ
            plt.legend(loc='center left', bbox_to_anchor=(1.0, 1.0), fontsize='small', handlelength=2.5)
            
            # ì €ì¥ ë° ë‹«ê¸°
            plt.savefig(os.path.join(self.path_output, filename), bbox_inches='tight')
            plt.close()


    def _plot_pr_curve(self, precision_dic, recall_dic):
        import itertools  # ìŠ¤íƒ€ì¼ ì¡°í•©ìš©
        plt.figure(figsize=(12, 10), constrained_layout=True)

        # ìƒ‰ìƒê³¼ ë¼ì¸ìŠ¤íƒ€ì¼ ì¡°í•© ìƒì„±ê¸°
        line_styles = ['-', '--'] # ['-', '--', '-.', ':']
        color_cycle = plt.rcParams['axes.prop_cycle'].by_key()['color']
        style_combinations = list(itertools.product(color_cycle, line_styles))

        # í´ë˜ìŠ¤ë³„ PR ê³¡ì„ 
        for i, cls in enumerate(self.class_list):
            precision = precision_dic[cls]
            recall = recall_dic[cls]
            color, linestyle = style_combinations[i % len(style_combinations)]
            plt.plot(recall, precision, label=cls, color=color, linestyle=linestyle, linewidth=2.0)

        # # í‰ê·  PR ê³¡ì„  ê³„ì‚°
        # num_points = len(next(iter(precision_dic.values())))  # ëª¨ë“  í´ë˜ìŠ¤ê°€ ë™ì¼ ê¸¸ì´ ê°€ì •
        # mean_precision = []
        # mean_recall = []

        # for i in range(num_points):
        #     p_list = [precision_dic[cls][i] for cls in self.class_list]
        #     r_list = [recall_dic[cls][i] for cls in self.class_list]
        #     mean_precision.append(sum(p_list) / len(p_list))
        #     mean_recall.append(sum(r_list) / len(r_list))

        # í‰ê·  PR ì„  ì¶”ê°€
        # plt.plot(mean_recall, mean_precision, label='mean', linestyle='--', color='black', linewidth=3)

        # ğŸ”½ í‰ê·  PR ê³„ì‚°ë§Œ ë³´ê°„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•˜ê²Œ ìˆ˜í–‰
        recall_range = np.linspace(0, 1, 101)
        mean_precision = np.zeros_like(recall_range)

        for cls in self.class_list:
            p = np.array(precision_dic[cls])
            r = np.array(recall_dic[cls])
            # ì¤‘ë³µ recall ì œê±°
            r, idx = np.unique(r, return_index=True)
            p = p[idx]
            interp_p = np.interp(recall_range, r, p, left=0, right=0)
            mean_precision += interp_p

        mean_precision /= len(self.class_list)
        # í‰ê·  PR ì„  ì¶”ê°€
        plt.plot(recall_range, mean_precision, label='mean', linestyle='--', color='black', linewidth=3)

        plt.xlabel('Recall')
        plt.ylabel('Precision')
        plt.title('Precision-Recall Curve')
        plt.legend(loc='lower left', fontsize='small', handlelength=2.5)
        plt.grid(True)
        plt.savefig(os.path.join(self.path_output, 'PR_curve.png'), bbox_inches='tight')
        plt.close()


    def filter_by_conf_thresh(self, annotations, conf_thresh):
        '''
        predì—ì„œ ë§Œì¡±í•˜ëŠ” conf. thresh.ë§Œ ë‚¨ê¸°ê³  ëª¨ë‘ ì‚­ì œ
        '''
        new_annotations = {}
        for file_name, bbox_list in annotations.items():
            new_bbox_list = []
            for info in bbox_list:
                if info['conf'] >= conf_thresh:
                    new_bbox_list.append(info)
            new_annotations[file_name] = new_bbox_list
        return new_annotations
    
    def _get_precision(self, tp, fp):
        if tp + fp == 0:
            return 1
        return tp / (tp + fp)

    def _get_recall(self, tp, fn):
        if tp + fn == 0:
            return 0
        return tp / (tp + fn)

    def _get_background_fp(self, bg_fp, total_pred):
        if total_pred == 0:
            return 0
        else:
            return bg_fp / total_pred
        
    def _get_annotations(self, path_annotations_folder, desc_txt):
        '''
        ì–´ë…¸í…Œì´ì…˜ì´ ë“¤ì–´ìˆëŠ” í´ë” ê²½ë¡œë¥¼ ì…ë ¥í•˜ë©´ íŒŒì¼ëª…ì— ë§ê²Œ bbox_listê°€ ë‹´ê¸´ dicìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
        '''
        dic_bbox_list = {}
        for annotations_file_name in tqdm(natsorted(os.listdir(path_annotations_folder)), desc=f'get annotation({desc_txt})'):
            dic_bbox_list[annotations_file_name] = self._get_annotation(f'{path_annotations_folder}/{annotations_file_name}')
        return dic_bbox_list

    def _get_annotation(self, path_annotation_file):
        '''
        ì–´ë…¸í…Œì´ì…˜ ê²½ë¡œë¥¼ ì…ë ¥í•˜ë©´ ì½ì–´ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜.
            - bbox_listë¡œ ë°˜í™˜í•˜ë©° confidenceê°€ ìˆëŠ” ê²½ìš°ëŠ” ë§ˆì§€ë§‰ ì¸ìì— í•˜ë‚˜ ë” ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•¨
            - ê¸°ë³¸ form: [{'class_name':'person', 'class_no':0, 'bbox':[x1, y1, x2, y2], 'conf':0.75}]
                1) confëŠ” ê²½ìš°ì— ë”°ë¼ ìë™ìœ¼ë¡œ ê°ì§€í•˜ì—¬ ìˆì„ìˆ˜ë„ ìˆê³  ì—†ì„ìˆ˜ë„ ìˆìŒ
        
        args:
        path_annotation_file = íŒŒì¼ ê²½ë¡œ

        return: 
        bbox_list
        '''
        with open(path_annotation_file, 'r', encoding='utf-8') as f:
            full_txt = f.read()
            split_by_enter = full_txt.split('\n')
        bbox_list = []
        for one_enter in split_by_enter:
            split_by_space = one_enter.split(' ')
            try:
                class_no = int(split_by_space[0])
            except:
                continue
            class_name = self.class_list[class_no]
            b1, b2, b3, b4 = split_by_space[1:5]
            b1, b2, b3, b4 = float(b1), float(b2), float(b3), float(b4)
            x1, y1, x2, y2 = yolo_to_x1y1x2y2([b1, b2, b3, b4])
            bbox = {'class_name': class_name, 'class_no': class_no, 'bbox': [x1, y1, x2, y2]}
            # confidenceëŠ” ì¸ë±ìŠ¤ 5ì— ìœ„ì¹˜í•¨ (ì •í™•í•œ ê°’ ì‚¬ìš©)
            if len(split_by_space) == 6:
                bbox['conf'] = float(split_by_space[5])
            bbox_list.append(bbox)
        return bbox_list

    def _pred_and_gt_mapping(self):
        '''
        predì™€ gtë¥¼ ë¶ˆëŸ¬ì™€ì„œ ì„œë¡œ ì´ë¹¨ ë¹ ì§„ ê³³ ì±„ì›Œë„£ì–´ì„œ ë§¤í•‘ ì‹œì¼œì„œ ë°˜í™˜
        '''
        # ì •ë‹µì§€ì™€ ì˜ˆì¸¡ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
        pred = self._get_annotations(self.path_pred, 'pred ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘')
        gt = self._get_annotations(self.path_gt, 'gt ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘')

        # ì˜ˆì¸¡ì§€ì˜ ê°œìˆ˜ê°€ ì •ë‹µì§€ë³´ë‹¤ ì ìœ¼ë©´ ë¹ ì§„ ì´ë¹¨ ì±„ì›Œë„£ê¸°
        if len(pred.keys()) != len(gt.keys()):
            pred = self._make_empty_pred(gt, pred)

        return pred, gt

    def _make_empty_pred(self, dic_gt_bbox_list, dic_pred_bbox_list):
        '''
        ë¡œì§ ì˜¤ë¥˜ë¥¼ ë§‰ê¸° ìœ„í•´ pred ê²°ê³¼ê°€ ì—†ì–´ë„ ë¹ˆ ê°ì§€ ê²°ê³¼ë¥¼ ë„£ì–´ì£¼ëŠ” ë¡œì§

        args:
        dic_gt_bbox_list = ì •ë‹µì§€ bbox_listê°€ ë‹´ê¸´ dic
        dic_pred_bbox_list = ì¶”ë¡  ê²°ê³¼ bbox_listê°€ ë‹´ê¸´ dic

        return:
        dic_pred_bbox_list = dic_gt_bbox_listê³¼ ê¸¸ì´ë¥¼ ë§ì¶˜ empty ì¶”ë¡  ê²°ê³¼ê°€ ì¶”ê°€ëœ dic
        '''
        for file_name, bbox_list in dic_gt_bbox_list.items():
            if file_name not in dic_pred_bbox_list:
                dic_pred_bbox_list[file_name] = []
        return dic_pred_bbox_list

    def draw_bgfp_auto(self, path_img):
        '''
        ìë™ìœ¼ë¡œ class_nameê³¼ conf_thresh ê¸°ì¤€ìœ¼ë¡œ Background FPë¥¼ ê·¸ë ¤ì£¼ëŠ” í•¨ìˆ˜
        '''        
        # for conf_thresh in tqdm(self.conf_thresh_list):
        for conf_thresh in tqdm([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]):
            for class_name in self.class_list:
                self._draw_bgfp(path_img, class_name, conf_thresh)
                
    def _draw_bgfp(self, path_img, class_name, conf_thresh):
        '''
        Background FPë§Œ ê·¸ë ¤ì„œ ë°˜í™˜í•´ì£¼ëŠ” ê¸°ëŠ¥
        - ë°˜ë“œì‹œ auto_run()ì´ ì„ í–‰ë˜ì–´ì•¼ í•¨. ê·¸ë˜ì•¼ self.bgfp_list ì•ˆì— bg_fp ì„±ë¶„ë“¤ì„ ì±„ìš¸ ìˆ˜ ìˆìŒ
        '''
        # í´ë” ìƒì„±
        write_path = f'{self.path_output}/draw_bgfp/{str(conf_thresh)}/{class_name}'
        makedirs(write_path)

        # ë°ì´í„° ìœ íš¨ì„± ì²´í¬
        try:
            # print(f'self.bgfp_list ê°œìˆ˜: {len(self.bgfp_list)}')
            pass
        except:
            print('self.bgfp_listê°€ ì•„ì§ ì„ ì–¸ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°˜ë“œì‹œ auto_run()ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.')
            return
        
        # conf_thresh ê¸°ì¤€ í•„í„°ë§
        filtered_list = []
        for result in self.bgfp_list:
            if result['conf'] >= conf_thresh and result['class_name'] == class_name:
                filtered_list.append(result)
        
        # label_name ê¸°ì¤€ ê·¸ë£¹í•‘
        filtered = {}
        for result in filtered_list:
            if result['label_name'] in filtered:
                filtered[result['label_name']].append(result)
            else:
                filtered[result['label_name']] = [result]
        
        # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
        full_img_list, name_img_list = [], []
        for img_name in listdir(path_img):
            full_img_list.append(img_name)
            name_img_list.append(name(img_name))

        # ê·¸ë¦¬ê¸°
        for label_name, results in filtered.items():
            # ì´ë¯¸ì§€ ì¡´ì¬ ìœ ë¬´ í™•ì¸
            if name(label_name) in name_img_list:
                img_idx = name_img_list.index(name(label_name))
                img_name = full_img_list[img_idx]
            else:
                print(f'ì´ë¯¸ì§€ ë§¤ì¹­ ì•ˆë¨: {label_name}')
                continue

            # gt ê·¸ë¦¬ê¸°
            for gt_name in listdir(self.path_gt):
                if name(gt_name) == name(img_name):
                    img = draw(img_path=f'{path_img}/{img_name}', label_path=f'{self.path_gt}/{gt_name}', write_path='return', color=[0,255,0])
                    break

            # ê·¸ë¦¬ê¸°
            bbox_list = []
            for result in results:
                class_name = result['class_name']
                x1, y1, x2, y2 = result['bbox']
                b1, b2, b3, b4 = x1y1x2y2_to_yolo([x1, y1, x2, y2])
                conf = result['conf']
                bbox_list.append([class_name, b1, b2, b3, b4, conf])
            draw(img_path=img, label_path=bbox_list, write_path=f'{write_path}/{img_name}')

    def rnd(self, no):
        '''ì†Œìˆ˜ì  ìë¦¬ìˆ˜ ë§ì¶°ì„œ ë°˜í™˜'''
        round_no = 3
        return round(no, round_no)